\subsubsection{Classifier}

The classifier used was a K-nearest neighbors classifier. It is easier to implement than other classifiers, yet it gives, most of the time, pretty good results.
It was developped in java from scratch, using the standard libraries, in a single class : KNearestNeighborsClassifier. It uses two important methods : getNeighbors() and getResponse().
getNeighbors returns the list of the k nearest neighbors, with k that can be parametrized when building the classifier.
getResponse give the classifier's guess for the author of the article.

Due to the disparity of the features considered, all value have been normalized on a 0 to 1 scale.


\subsubsection{Problems}
The problem with this classifier, is that the results are not as good as we hoped. We knew the style would be harder to detect, but even on the training set the success ration is under 50\%. Knowing by heart is not the solution, so we didn't expected a 100\% success rate, but still it's a little bit deceiving. 

But, where do these poor results come from ? It doesn't seem to be a problem of implementation, but it's almost sure it comes from the features. Indeed, we lack of recognisable features. Moreover, some of them could be deduced from the others : The number of lines is the number of ".", "?" and "!" for example.